{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torchvision.datasets as tvds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tvds.EMNIST(\"./datasets\", split='digits', train=True, download=True)\n",
    "test_set = tvds.EMNIST(\"./datasets\", split='digits', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240000, 28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0177, 0.0147, 0.0170, 0.0163, 0.0148, 0.0165, 0.0159, 0.0164, 0.0158,\n",
       "         0.0153, 0.0153, 0.0163, 0.0161, 0.0163, 0.0170, 0.0171, 0.0174, 0.0158,\n",
       "         0.0165, 0.0159, 0.0177, 0.0160, 0.0154, 0.0156, 0.0152, 0.0165, 0.0150,\n",
       "         0.0156, 0.0170, 0.0160, 0.0152, 0.0155, 0.0152, 0.0179, 0.0153, 0.0158,\n",
       "         0.0173, 0.0157, 0.0172, 0.0156, 0.0160, 0.0157, 0.0171, 0.0149, 0.0168,\n",
       "         0.0163, 0.0157, 0.0155, 0.0158, 0.0177, 0.0163, 0.0164, 0.0165, 0.0145,\n",
       "         0.0165, 0.0156, 0.0172, 0.0153, 0.0151, 0.0166, 0.0167, 0.0169]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.classifier_act = nn.Softmax(dim=1)\n",
    "        # ((in+2p-d*(k-1)-1) / s) + 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3) # 26x26 \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride = 2) # 11x11\n",
    "        self.conv3 = nn.Conv2d(32, 16, 3, stride = 2) # 5x5\n",
    "\n",
    "        self.classifier = nn.Linear(400, 62)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1) # flatten the data\n",
    "\n",
    "        outs = self.classifier(x)\n",
    "        return self.classifier_act(outs)\n",
    "\n",
    "    def set_config(self, optimizer, loss_fn, device=\"cpu\"):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        outs = self.forward(x)\n",
    "        loss = self.loss_fn(outs, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return loss.cpu().item()\n",
    "\n",
    "model = Baseline()\n",
    "\n",
    "model(torch.rand((1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x = torch.utils.data.DataLoader(train_set.data, batch_size=256)\n",
    "for i in x:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.x = dataset.data\n",
    "        self.y = dataset.targets\n",
    "        self.classes = dataset.classes\n",
    "        self.class_to_idx = dataset.class_to_idx\n",
    "\n",
    "        assert len(self.x)==len(self.y), \"Number of samples doesn't match!\"\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = list(idx)\n",
    "        \n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        x = torch.unsqueeze(x, 0) if type(idx)==int else torch.unsqueeze(x, 1)\n",
    "\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "train_dataset = Dataset(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:09<00:00, 33.49it/s]\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.6940 | Validation loss: 3.6633 | took 11.6496 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def split_data(dataset, ratio=.3):\n",
    "    N = int(len(dataset)*ratio)\n",
    "    split1, split2 = torch.utils.data.random_split(dataset, [len(dataset) - N, N])\n",
    "    return split1, split2\n",
    "\n",
    "def validate(loader, model):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x_batch, y_batch = batch[0].to(model.device, dtype=torch.float32), batch[1].to(model.device)\n",
    "            outs = model(x_batch)\n",
    "            loss = model.loss_fn(outs, y_batch)\n",
    "            losses.append(loss.cpu().item())\n",
    "    return sum(losses)/len(losses)\n",
    "\n",
    "def train_model(train_loader, val_loader, model, loss_fn, optimizer, device='cpu', n_epochs=1, verbose=0):\n",
    "    model.set_config(optimizer=optimizer, loss_fn=loss_fn, device=device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(n_epochs)):\n",
    "        epoch_train_loss = 0\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            x_batch, y_batch = batch[0].to(model.device, dtype=torch.float32), batch[1].to(model.device)\n",
    "            train_loss = model.train_step(x_batch, y_batch)\n",
    "            epoch_train_loss += train_loss / len(train_loader)\n",
    "        \n",
    "        # validate\n",
    "        epoch_val_loss = validate(val_loader, model)\n",
    "\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        t1 = time.time()\n",
    "        print(\"Training loss: %.4f | Validation loss: %.4f | took %.4f secs\"%(epoch_train_loss, epoch_val_loss, t1-t0))\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "train_data, val_data = split_data(train_dataset)\n",
    "train_loader, val_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE), torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = Baseline()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else 'cpu')\n",
    "print(\"Training on: %s\"%device)\n",
    "losses = train_model(train_loader, val_loader, model, loss_fn, optimizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(len(i[1]))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab3a57f480ffab936d0424ae6d6f787933c94dcd217034de2e35ec556cfa4d8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
